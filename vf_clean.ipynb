{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:46.215085Z",
     "start_time": "2025-03-10T03:03:44.891367Z"
    }
   },
   "source": [
    "import os\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import common GIS tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from matplotlib.cm import RdYlGn,jet,RdBu\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import stackstac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "from odc.stac import stac_load"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate NDVI\n",
    "training_data = pd.read_csv(\"../data_test/training_data_uhi_index.csv\")\n",
    "print(training_data.columns)\n",
    "training_data['datetime'] = pd.to_datetime(training_data['datetime'], format='%d-%m-%Y %H:%M')\n",
    "training_data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:46.246511Z",
     "start_time": "2025-03-10T03:03:46.220632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Longitude', 'Latitude', 'datetime', 'UHI Index'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          Longitude      Latitude                       datetime     UHI Index\n",
       "count  11229.000000  11229.000000                          11229  11229.000000\n",
       "mean     -73.933927     40.808800  2021-07-24 15:34:29.056906240      1.000001\n",
       "min      -73.994457     40.758792            2021-07-24 15:01:00      0.956122\n",
       "25%      -73.955703     40.790905            2021-07-24 15:22:00      0.988577\n",
       "50%      -73.932968     40.810688            2021-07-24 15:36:00      1.000237\n",
       "75%      -73.909647     40.824515            2021-07-24 15:48:00      1.011176\n",
       "max      -73.879458     40.859497            2021-07-24 15:59:00      1.046036\n",
       "std        0.028253      0.023171                            NaN      0.016238"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>datetime</th>\n",
       "      <th>UHI Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229</td>\n",
       "      <td>11229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-73.933927</td>\n",
       "      <td>40.808800</td>\n",
       "      <td>2021-07-24 15:34:29.056906240</td>\n",
       "      <td>1.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-73.994457</td>\n",
       "      <td>40.758792</td>\n",
       "      <td>2021-07-24 15:01:00</td>\n",
       "      <td>0.956122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-73.955703</td>\n",
       "      <td>40.790905</td>\n",
       "      <td>2021-07-24 15:22:00</td>\n",
       "      <td>0.988577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-73.932968</td>\n",
       "      <td>40.810688</td>\n",
       "      <td>2021-07-24 15:36:00</td>\n",
       "      <td>1.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-73.909647</td>\n",
       "      <td>40.824515</td>\n",
       "      <td>2021-07-24 15:48:00</td>\n",
       "      <td>1.011176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-73.879458</td>\n",
       "      <td>40.859497</td>\n",
       "      <td>2021-07-24 15:59:00</td>\n",
       "      <td>1.046036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028253</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the bounds for doing an archive data search\n",
    "# bounds = (min_lon, min_lat, max_lon, max_lat)\n",
    "lower_left = (40.75, -74.01)\n",
    "upper_right = (40.88, -73.86)\n",
    "bounds = (lower_left[1], lower_left[0], upper_right[1], upper_right[0])\n",
    "time_window = \"2021-07-23/2021-07-25\"\n",
    "height = 100\n",
    "width = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:46.540618Z",
     "start_time": "2025-03-10T03:03:46.525089Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search = stac.search(\n",
    "    bbox=bounds,\n",
    "    datetime=time_window,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 30}},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:47.581629Z",
     "start_time": "2025-03-10T03:03:46.572317Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "items = list(search.get_items())\n",
    "print('This is the number of scenes that touch our region:',len(items))\n",
    "signed_items = [planetary_computer.sign(item).to_dict() for item in items]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:48.796317Z",
     "start_time": "2025-03-10T03:03:47.613979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of scenes that touch our region: 1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "resolution = 10  # meters per pixel\n",
    "scale = resolution / 111320.0 # degrees per pixel for crs=4326"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:48.811449Z",
     "start_time": "2025-03-10T03:03:48.799370Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "data = stac_load(\n",
    "    items,\n",
    "    bands=[\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"],\n",
    "    crs=\"EPSG:4326\",  # Latitude-Longitude\n",
    "    resolution=scale,  # Degrees\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    "    dtype=\"uint16\",\n",
    "    patch_url=planetary_computer.sign,\n",
    "    bbox=bounds\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:03:48.857343Z",
     "start_time": "2025-03-10T03:03:48.827716Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "df = train_feat = data.to_dataframe().reset_index()\n",
    "print(df.head())\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['time'] = df['time'].dt.strftime('%d-%m-%Y %H:%M')\n",
    "display(df)\n",
    "training_data['datetime'] = pd.to_datetime(training_data['datetime'], format='%d-%m-%Y %H:%M')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:04:11.621127Z",
     "start_time": "2025-03-10T03:03:48.873648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    latitude  longitude                    time  spatial_ref  B01  B02   B03  \\\n",
      "0  40.880031 -74.010016 2021-07-24 15:49:11.024         4326  666  639   728   \n",
      "1  40.880031 -74.009926 2021-07-24 15:49:11.024         4326  666  639   728   \n",
      "2  40.880031 -74.009837 2021-07-24 15:49:11.024         4326  666  395   579   \n",
      "3  40.880031 -74.009747 2021-07-24 15:49:11.024         4326  666  562   775   \n",
      "4  40.880031 -74.009657 2021-07-24 15:49:11.024         4326  710  919  1036   \n",
      "\n",
      "    B04   B05   B06   B07   B08   B8A   B11   B12  \n",
      "0   839  1023  2034  2064  1440  2438  1578  1083  \n",
      "1   839  1023  2034  2064  1440  2438  1578  1083  \n",
      "2   415   889  1850  2216  2354  2133  1554  1029  \n",
      "3   688   889  1850  2216  2270  2133  1554  1029  \n",
      "4  1108  1201  1566  1757  1584  1908  1742  1353  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          latitude  longitude              time  spatial_ref   B01   B02  \\\n",
       "0        40.880031 -74.010016  24-07-2021 15:49         4326   666   639   \n",
       "1        40.880031 -74.009926  24-07-2021 15:49         4326   666   639   \n",
       "2        40.880031 -74.009837  24-07-2021 15:49         4326   666   395   \n",
       "3        40.880031 -74.009747  24-07-2021 15:49         4326   666   562   \n",
       "4        40.880031 -74.009657  24-07-2021 15:49         4326   710   919   \n",
       "...            ...        ...               ...          ...   ...   ...   \n",
       "2419603  40.750045 -73.860358  24-07-2021 15:49         4326  1175  1412   \n",
       "2419604  40.750045 -73.860268  24-07-2021 15:49         4326  1175   980   \n",
       "2419605  40.750045 -73.860178  24-07-2021 15:49         4326  1182  1202   \n",
       "2419606  40.750045 -73.860088  24-07-2021 15:49         4326  1182  1220   \n",
       "2419607  40.750045 -73.859998  24-07-2021 15:49         4326  1182  1220   \n",
       "\n",
       "          B03   B04   B05   B06   B07   B08   B8A   B11   B12  \n",
       "0         728   839  1023  2034  2064  1440  2438  1578  1083  \n",
       "1         728   839  1023  2034  2064  1440  2438  1578  1083  \n",
       "2         579   415   889  1850  2216  2354  2133  1554  1029  \n",
       "3         775   688   889  1850  2216  2270  2133  1554  1029  \n",
       "4        1036  1108  1201  1566  1757  1584  1908  1742  1353  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2419603  1362  1602  1858  1940  1908  1588  2050  2202  1989  \n",
       "2419604  1290  1444  1858  1940  1908  1684  2050  2202  1989  \n",
       "2419605  1326  1416  1530  1557  1903  1842  1797  1909  1721  \n",
       "2419606  1398  1418  1530  1557  1903  1788  1797  1909  1721  \n",
       "2419607  1398  1418  1530  1557  1903  1788  1797  1909  1721  \n",
       "\n",
       "[2419608 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>spatial_ref</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.880031</td>\n",
       "      <td>-74.010016</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>666</td>\n",
       "      <td>639</td>\n",
       "      <td>728</td>\n",
       "      <td>839</td>\n",
       "      <td>1023</td>\n",
       "      <td>2034</td>\n",
       "      <td>2064</td>\n",
       "      <td>1440</td>\n",
       "      <td>2438</td>\n",
       "      <td>1578</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.880031</td>\n",
       "      <td>-74.009926</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>666</td>\n",
       "      <td>639</td>\n",
       "      <td>728</td>\n",
       "      <td>839</td>\n",
       "      <td>1023</td>\n",
       "      <td>2034</td>\n",
       "      <td>2064</td>\n",
       "      <td>1440</td>\n",
       "      <td>2438</td>\n",
       "      <td>1578</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.880031</td>\n",
       "      <td>-74.009837</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>666</td>\n",
       "      <td>395</td>\n",
       "      <td>579</td>\n",
       "      <td>415</td>\n",
       "      <td>889</td>\n",
       "      <td>1850</td>\n",
       "      <td>2216</td>\n",
       "      <td>2354</td>\n",
       "      <td>2133</td>\n",
       "      <td>1554</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.880031</td>\n",
       "      <td>-74.009747</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>666</td>\n",
       "      <td>562</td>\n",
       "      <td>775</td>\n",
       "      <td>688</td>\n",
       "      <td>889</td>\n",
       "      <td>1850</td>\n",
       "      <td>2216</td>\n",
       "      <td>2270</td>\n",
       "      <td>2133</td>\n",
       "      <td>1554</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.880031</td>\n",
       "      <td>-74.009657</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>710</td>\n",
       "      <td>919</td>\n",
       "      <td>1036</td>\n",
       "      <td>1108</td>\n",
       "      <td>1201</td>\n",
       "      <td>1566</td>\n",
       "      <td>1757</td>\n",
       "      <td>1584</td>\n",
       "      <td>1908</td>\n",
       "      <td>1742</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419603</th>\n",
       "      <td>40.750045</td>\n",
       "      <td>-73.860358</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1175</td>\n",
       "      <td>1412</td>\n",
       "      <td>1362</td>\n",
       "      <td>1602</td>\n",
       "      <td>1858</td>\n",
       "      <td>1940</td>\n",
       "      <td>1908</td>\n",
       "      <td>1588</td>\n",
       "      <td>2050</td>\n",
       "      <td>2202</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419604</th>\n",
       "      <td>40.750045</td>\n",
       "      <td>-73.860268</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1175</td>\n",
       "      <td>980</td>\n",
       "      <td>1290</td>\n",
       "      <td>1444</td>\n",
       "      <td>1858</td>\n",
       "      <td>1940</td>\n",
       "      <td>1908</td>\n",
       "      <td>1684</td>\n",
       "      <td>2050</td>\n",
       "      <td>2202</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419605</th>\n",
       "      <td>40.750045</td>\n",
       "      <td>-73.860178</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1182</td>\n",
       "      <td>1202</td>\n",
       "      <td>1326</td>\n",
       "      <td>1416</td>\n",
       "      <td>1530</td>\n",
       "      <td>1557</td>\n",
       "      <td>1903</td>\n",
       "      <td>1842</td>\n",
       "      <td>1797</td>\n",
       "      <td>1909</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419606</th>\n",
       "      <td>40.750045</td>\n",
       "      <td>-73.860088</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1182</td>\n",
       "      <td>1220</td>\n",
       "      <td>1398</td>\n",
       "      <td>1418</td>\n",
       "      <td>1530</td>\n",
       "      <td>1557</td>\n",
       "      <td>1903</td>\n",
       "      <td>1788</td>\n",
       "      <td>1797</td>\n",
       "      <td>1909</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419607</th>\n",
       "      <td>40.750045</td>\n",
       "      <td>-73.859998</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1182</td>\n",
       "      <td>1220</td>\n",
       "      <td>1398</td>\n",
       "      <td>1418</td>\n",
       "      <td>1530</td>\n",
       "      <td>1557</td>\n",
       "      <td>1903</td>\n",
       "      <td>1788</td>\n",
       "      <td>1797</td>\n",
       "      <td>1909</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2419608 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "training_data.rename(columns={'Latitude': 'latitude', 'Longitude': 'longitude'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:04:11.652182Z",
     "start_time": "2025-03-10T03:04:11.645632Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Função para extrair as features de training_data para um ponto (lat, lon)\n",
    "def extract_features_from_dataframe(lat, lon, df):\n",
    "    # Calcula a distância euclidiana entre (lat, lon) e todas as linhas de df\n",
    "    df[\"distance\"] = np.sqrt((df[\"latitude\"] - lat)**2 + (df[\"longitude\"] - lon)**2)\n",
    "    # Seleciona a linha com a menor distância (ponto mais próximo)\n",
    "    closest_row = df.loc[df[\"distance\"].idxmin()]\n",
    "    # Retorna os valores dessa linha como dicionário\n",
    "    return closest_row.to_dict()\n",
    "\n",
    "# Itera sobre as linhas de df e extrai features do training_data (que contém o UHI Index)\n",
    "features = []\n",
    "for idx, row in df.iterrows():\n",
    "    lat, lon = row[\"latitude\"], row[\"longitude\"]\n",
    "    features.append(extract_features_from_dataframe(lat, lon, training_data))\n",
    "\n",
    "# Cria um DataFrame com as features extraídas\n",
    "extracted_features = pd.DataFrame(features)\n",
    "\n",
    "# Realiza um left merge de df com as features extraídas usando o índice\n",
    "df_with_features = df.merge(extracted_features, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Remove colunas duplicadas, se existirem\n",
    "df_with_features = df_with_features.loc[:, ~df_with_features.columns.duplicated()]\n",
    "\n",
    "# Converte a distância de graus para metros (aproximadamente no equador)\n",
    "conversion_factor = 111320  # metros por grau\n",
    "df_with_features['distance_meters'] = df_with_features['distance'] * conversion_factor\n",
    "\n",
    "# Agora, df_with_features contém o \"UHI Index\" e demais features extraídas de training_data\n",
    "print(df_with_features.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:16:16.755172Z",
     "start_time": "2025-03-10T03:04:11.683801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude_x  longitude_x              time  spatial_ref  B01  B02   B03  \\\n",
      "0   40.880031   -74.010016  24-07-2021 15:49         4326  666  639   728   \n",
      "1   40.880031   -74.009926  24-07-2021 15:49         4326  666  639   728   \n",
      "2   40.880031   -74.009837  24-07-2021 15:49         4326  666  395   579   \n",
      "3   40.880031   -74.009747  24-07-2021 15:49         4326  666  562   775   \n",
      "4   40.880031   -74.009657  24-07-2021 15:49         4326  710  919  1036   \n",
      "\n",
      "    B04   B05   B06  ...   B08   B8A   B11   B12  longitude_y  latitude_y  \\\n",
      "0   839  1023  2034  ...  1440  2438  1578  1083   -73.938388   40.853352   \n",
      "1   839  1023  2034  ...  1440  2438  1578  1083   -73.938388   40.853352   \n",
      "2   415   889  1850  ...  2354  2133  1554  1029   -73.938388   40.853352   \n",
      "3   688   889  1850  ...  2270  2133  1554  1029   -73.938388   40.853352   \n",
      "4  1108  1201  1566  ...  1584  1908  1742  1353   -73.938388   40.853352   \n",
      "\n",
      "             datetime UHI Index  distance  distance_meters  \n",
      "0 2021-07-24 15:28:00  1.011056  0.076435      8508.744508  \n",
      "1 2021-07-24 15:28:00  1.011056  0.076351      8499.374146  \n",
      "2 2021-07-24 15:28:00  1.011056  0.076267      8490.005221  \n",
      "3 2021-07-24 15:28:00  1.011056  0.076183      8480.637738  \n",
      "4 2021-07-24 15:28:00  1.011056  0.076098      8471.271700  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "df_with_features_100 = df_with_features[df_with_features['distance_meters']<100]\n",
    "df_with_features_80 = df_with_features[df_with_features['distance_meters']<80]\n",
    "df_with_features_150 = df_with_features[df_with_features['distance_meters']<150]\n",
    "df_with_features_200 = df_with_features[df_with_features['distance_meters']<200]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:16:16.900280Z",
     "start_time": "2025-03-10T03:16:16.786624Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "training_data_with_features = df_with_features_150\n",
    "print(training_data_with_features.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:16:16.915924Z",
     "start_time": "2025-03-10T03:16:16.900280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304467, 21)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Exemplo: Criação de NDVI e SAVI\n",
    "training_data_with_features['NDVI'] = (training_data_with_features['B08'] - training_data_with_features['B04']) / (training_data_with_features['B08'] + training_data_with_features['B04'] + 1e-6)\n",
    "L = 0.5\n",
    "training_data_with_features['SAVI'] = ((training_data_with_features['B08'] - training_data_with_features['B04']) * (1 + L)) / (training_data_with_features['B08'] + training_data_with_features['B04'] + L + 1e-6)\n",
    "\n",
    "# Criação de NDBI\n",
    "training_data_with_features['NDBI'] = (training_data_with_features['B11'] - training_data_with_features['B08']) / (training_data_with_features['B11'] + training_data_with_features['B08'] + 1e-6)\n",
    "\n",
    "# Criação de MNDWI\n",
    "training_data_with_features['MNDWI'] = (training_data_with_features['B03'] - training_data_with_features['B11']) / (training_data_with_features['B03'] + training_data_with_features['B11'] + 1e-6)\n",
    "\n",
    "# Criação de EVI\n",
    "training_data_with_features['EVI'] = 2.5 * (training_data_with_features['B08'] - training_data_with_features['B04']) / (training_data_with_features['B08'] + 6 * training_data_with_features['B04'] - 7.5 * training_data_with_features['B02'] + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:16:16.974390Z",
     "start_time": "2025-03-10T03:16:16.946020Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "print(training_data_with_features.columns)\n",
    "training_data_with_features = training_data_with_features.drop(columns=[\"latitude_x\",\n",
    "                                                                        \"longitude_y\",\n",
    "                                                                        \"latitude_x\",\n",
    "                                                                        \"longitude_y\",\n",
    "                                                                        'datetime',\n",
    "                                                                        'time'], axis=1, errors = 'ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:16:17.017277Z",
     "start_time": "2025-03-10T03:16:17.000619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['latitude_x', 'longitude_x', 'time', 'spatial_ref', 'B01', 'B02', 'B03',\n",
      "       'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12', 'longitude_y',\n",
      "       'latitude_y', 'datetime', 'UHI Index', 'distance', 'distance_meters',\n",
      "       'NDVI', 'SAVI', 'NDBI', 'MNDWI', 'EVI'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_outliers_iqr(df, factor=3):\n",
    "    print(df)\n",
    "    df.reset_index(drop=True)\n",
    "    df_clean = df.copy()\n",
    "    # Get list of numeric columns\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "\n",
    "        # Keep rows within the bounds\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame\n",
    "df_clean_factor3 = remove_outliers_iqr(training_data_with_features, factor=3)\n",
    "df_clean_factor4 = remove_outliers_iqr(training_data_with_features, factor=4)\n",
    "df_clean_factor5 = remove_outliers_iqr(training_data_with_features, factor=5)\n",
    "df_clean_factor2 = remove_outliers_iqr(training_data_with_features, factor=2)\n",
    "print(\"Data shape before outlier removal:\", training_data_with_features.shape)\n",
    "print(\"Data shape after outlier removal:\", df_clean_factor3.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T03:16:18.942324Z",
     "start_time": "2025-03-10T03:16:17.039504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         longitude_x  spatial_ref  B01  B02  B03  B04   B05   B06   B07   B08  \\\n",
      "358458    -73.932402         4326  341  792  941  843   909  1985  2300  2130   \n",
      "358459    -73.932312         4326  310  616  791  810   929  1627  2130  1764   \n",
      "358460    -73.932222         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358461    -73.932133         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358462    -73.932043         4326  310  444  613  530   914  2601  3347  2864   \n",
      "...              ...          ...  ...  ...  ...  ...   ...   ...   ...   ...   \n",
      "2279803   -73.959801         4326  889  532  777  585  1100  2664  2932  3208   \n",
      "2279804   -73.959711         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279805   -73.959621         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279806   -73.959531         4326  956  731  877  810  1236  1834  2272  2876   \n",
      "2279807   -73.959441         4326  956  843  975  862  1236  1834  2272  2182   \n",
      "\n",
      "         ...   B12  latitude_y  UHI Index  distance  distance_meters  \\\n",
      "358458   ...   895   40.859495   1.021394  0.001339       149.087249   \n",
      "358459   ...  1040   40.859495   1.021394  0.001324       147.393887   \n",
      "358460   ...  1040   40.859495   1.021394  0.001315       146.365665   \n",
      "358461   ...  1040   40.859495   1.021394  0.001312       146.016636   \n",
      "358462   ...   929   40.859497   1.021394  0.001310       145.838917   \n",
      "...      ...   ...         ...        ...       ...              ...   \n",
      "2279803  ...   997   40.758792   0.979081  0.001291       143.718065   \n",
      "2279804  ...   997   40.758795   0.979081  0.001296       144.236875   \n",
      "2279805  ...   997   40.758795   0.979081  0.001303       145.077001   \n",
      "2279806  ...  1042   40.758795   0.979081  0.001317       146.596030   \n",
      "2279807  ...  1042   40.758795   0.979081  0.001336       148.773170   \n",
      "\n",
      "             NDVI      SAVI       NDBI      MNDWI       EVI  \n",
      "358458   0.432896  0.649235  17.978664  26.858678  2.576061  \n",
      "358459   0.370629  0.555836  19.951100  28.194432  1.189526  \n",
      "358460   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358461   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358462   0.687684  1.031374  14.127305  27.963991  2.149171  \n",
      "...           ...       ...        ...        ...       ...  \n",
      "2279803  0.691537  1.037169  13.129668  26.462137  2.402895  \n",
      "2279804  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279805  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279806  0.560499  0.840635  14.621326  27.154812  2.290974  \n",
      "2279807  0.433640  0.650353  17.555345  26.124598  3.196126  \n",
      "\n",
      "[304467 rows x 22 columns]\n",
      "         longitude_x  spatial_ref  B01  B02  B03  B04   B05   B06   B07   B08  \\\n",
      "358458    -73.932402         4326  341  792  941  843   909  1985  2300  2130   \n",
      "358459    -73.932312         4326  310  616  791  810   929  1627  2130  1764   \n",
      "358460    -73.932222         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358461    -73.932133         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358462    -73.932043         4326  310  444  613  530   914  2601  3347  2864   \n",
      "...              ...          ...  ...  ...  ...  ...   ...   ...   ...   ...   \n",
      "2279803   -73.959801         4326  889  532  777  585  1100  2664  2932  3208   \n",
      "2279804   -73.959711         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279805   -73.959621         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279806   -73.959531         4326  956  731  877  810  1236  1834  2272  2876   \n",
      "2279807   -73.959441         4326  956  843  975  862  1236  1834  2272  2182   \n",
      "\n",
      "         ...   B12  latitude_y  UHI Index  distance  distance_meters  \\\n",
      "358458   ...   895   40.859495   1.021394  0.001339       149.087249   \n",
      "358459   ...  1040   40.859495   1.021394  0.001324       147.393887   \n",
      "358460   ...  1040   40.859495   1.021394  0.001315       146.365665   \n",
      "358461   ...  1040   40.859495   1.021394  0.001312       146.016636   \n",
      "358462   ...   929   40.859497   1.021394  0.001310       145.838917   \n",
      "...      ...   ...         ...        ...       ...              ...   \n",
      "2279803  ...   997   40.758792   0.979081  0.001291       143.718065   \n",
      "2279804  ...   997   40.758795   0.979081  0.001296       144.236875   \n",
      "2279805  ...   997   40.758795   0.979081  0.001303       145.077001   \n",
      "2279806  ...  1042   40.758795   0.979081  0.001317       146.596030   \n",
      "2279807  ...  1042   40.758795   0.979081  0.001336       148.773170   \n",
      "\n",
      "             NDVI      SAVI       NDBI      MNDWI       EVI  \n",
      "358458   0.432896  0.649235  17.978664  26.858678  2.576061  \n",
      "358459   0.370629  0.555836  19.951100  28.194432  1.189526  \n",
      "358460   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358461   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358462   0.687684  1.031374  14.127305  27.963991  2.149171  \n",
      "...           ...       ...        ...        ...       ...  \n",
      "2279803  0.691537  1.037169  13.129668  26.462137  2.402895  \n",
      "2279804  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279805  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279806  0.560499  0.840635  14.621326  27.154812  2.290974  \n",
      "2279807  0.433640  0.650353  17.555345  26.124598  3.196126  \n",
      "\n",
      "[304467 rows x 22 columns]\n",
      "         longitude_x  spatial_ref  B01  B02  B03  B04   B05   B06   B07   B08  \\\n",
      "358458    -73.932402         4326  341  792  941  843   909  1985  2300  2130   \n",
      "358459    -73.932312         4326  310  616  791  810   929  1627  2130  1764   \n",
      "358460    -73.932222         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358461    -73.932133         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358462    -73.932043         4326  310  444  613  530   914  2601  3347  2864   \n",
      "...              ...          ...  ...  ...  ...  ...   ...   ...   ...   ...   \n",
      "2279803   -73.959801         4326  889  532  777  585  1100  2664  2932  3208   \n",
      "2279804   -73.959711         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279805   -73.959621         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279806   -73.959531         4326  956  731  877  810  1236  1834  2272  2876   \n",
      "2279807   -73.959441         4326  956  843  975  862  1236  1834  2272  2182   \n",
      "\n",
      "         ...   B12  latitude_y  UHI Index  distance  distance_meters  \\\n",
      "358458   ...   895   40.859495   1.021394  0.001339       149.087249   \n",
      "358459   ...  1040   40.859495   1.021394  0.001324       147.393887   \n",
      "358460   ...  1040   40.859495   1.021394  0.001315       146.365665   \n",
      "358461   ...  1040   40.859495   1.021394  0.001312       146.016636   \n",
      "358462   ...   929   40.859497   1.021394  0.001310       145.838917   \n",
      "...      ...   ...         ...        ...       ...              ...   \n",
      "2279803  ...   997   40.758792   0.979081  0.001291       143.718065   \n",
      "2279804  ...   997   40.758795   0.979081  0.001296       144.236875   \n",
      "2279805  ...   997   40.758795   0.979081  0.001303       145.077001   \n",
      "2279806  ...  1042   40.758795   0.979081  0.001317       146.596030   \n",
      "2279807  ...  1042   40.758795   0.979081  0.001336       148.773170   \n",
      "\n",
      "             NDVI      SAVI       NDBI      MNDWI       EVI  \n",
      "358458   0.432896  0.649235  17.978664  26.858678  2.576061  \n",
      "358459   0.370629  0.555836  19.951100  28.194432  1.189526  \n",
      "358460   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358461   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358462   0.687684  1.031374  14.127305  27.963991  2.149171  \n",
      "...           ...       ...        ...        ...       ...  \n",
      "2279803  0.691537  1.037169  13.129668  26.462137  2.402895  \n",
      "2279804  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279805  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279806  0.560499  0.840635  14.621326  27.154812  2.290974  \n",
      "2279807  0.433640  0.650353  17.555345  26.124598  3.196126  \n",
      "\n",
      "[304467 rows x 22 columns]\n",
      "         longitude_x  spatial_ref  B01  B02  B03  B04   B05   B06   B07   B08  \\\n",
      "358458    -73.932402         4326  341  792  941  843   909  1985  2300  2130   \n",
      "358459    -73.932312         4326  310  616  791  810   929  1627  2130  1764   \n",
      "358460    -73.932222         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358461    -73.932133         4326  310  749  803  750   929  1627  2130  1778   \n",
      "358462    -73.932043         4326  310  444  613  530   914  2601  3347  2864   \n",
      "...              ...          ...  ...  ...  ...  ...   ...   ...   ...   ...   \n",
      "2279803   -73.959801         4326  889  532  777  585  1100  2664  2932  3208   \n",
      "2279804   -73.959711         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279805   -73.959621         4326  889  637  850  688  1100  2664  2932  3440   \n",
      "2279806   -73.959531         4326  956  731  877  810  1236  1834  2272  2876   \n",
      "2279807   -73.959441         4326  956  843  975  862  1236  1834  2272  2182   \n",
      "\n",
      "         ...   B12  latitude_y  UHI Index  distance  distance_meters  \\\n",
      "358458   ...   895   40.859495   1.021394  0.001339       149.087249   \n",
      "358459   ...  1040   40.859495   1.021394  0.001324       147.393887   \n",
      "358460   ...  1040   40.859495   1.021394  0.001315       146.365665   \n",
      "358461   ...  1040   40.859495   1.021394  0.001312       146.016636   \n",
      "358462   ...   929   40.859497   1.021394  0.001310       145.838917   \n",
      "...      ...   ...         ...        ...       ...              ...   \n",
      "2279803  ...   997   40.758792   0.979081  0.001291       143.718065   \n",
      "2279804  ...   997   40.758795   0.979081  0.001296       144.236875   \n",
      "2279805  ...   997   40.758795   0.979081  0.001303       145.077001   \n",
      "2279806  ...  1042   40.758795   0.979081  0.001317       146.596030   \n",
      "2279807  ...  1042   40.758795   0.979081  0.001336       148.773170   \n",
      "\n",
      "             NDVI      SAVI       NDBI      MNDWI       EVI  \n",
      "358458   0.432896  0.649235  17.978664  26.858678  2.576061  \n",
      "358459   0.370629  0.555836  19.951100  28.194432  1.189526  \n",
      "358460   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358461   0.406646  0.609848  19.861838  28.053224  3.885110  \n",
      "358462   0.687684  1.031374  14.127305  27.963991  2.149171  \n",
      "...           ...       ...        ...        ...       ...  \n",
      "2279803  0.691537  1.037169  13.129668  26.462137  2.402895  \n",
      "2279804  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279805  0.666667  0.999879  12.487662  25.723370  2.464625  \n",
      "2279806  0.560499  0.840635  14.621326  27.154812  2.290974  \n",
      "2279807  0.433640  0.650353  17.555345  26.124598  3.196126  \n",
      "\n",
      "[304467 rows x 22 columns]\n",
      "Data shape before outlier removal: (304467, 22)\n",
      "Data shape after outlier removal: (232278, 22)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Carregar Dados e Pré-processamento\n",
    "# ------------------------------\n",
    "# Supondo que `df1_filtered` seja o dataset processado disponível\n",
    "# data = df1_filtered.copy()\n",
    "# data = df_clean_factor3.copy()\n",
    "data = df_clean_factor5.copy()\n",
    "data = df_clean_factor4.copy()\n",
    "\n",
    "# Remova as colunas irrelevantes\n",
    "cols_to_drop = [\"latitude_x\",\n",
    "                \"longitude_y\",\n",
    "                \"latitude_y\",\n",
    "                \"longitude_x\",\n",
    "                \"latitude\",\n",
    "                \"longitude\",\n",
    "                \"datetime\",\n",
    "                \"distance\",\n",
    "                \"distance_meters\",\n",
    "                \"time\",\n",
    "                \"spatial_ref\",\n",
    "                \"EVI\"]\n",
    "data = data.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Defina a variável target\n",
    "target = \"UHI Index\"\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Construção do Pipeline\n",
    "# ------------------------------\n",
    "pipeline = Pipeline([\n",
    "    (\"select_from_model\", SelectFromModel(\n",
    "        estimator=ExtraTreesRegressor(n_estimators=300, random_state=42),\n",
    "        threshold=\"1*mean\"\n",
    "    )),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", ExtraTreesRegressor(random_state=42, n_estimators=600, max_depth=150, min_samples_split=2))\n",
    "])\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Validação Cruzada (Cross-Validation)\n",
    "# ------------------------------\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-Fold Cross-Validation\n",
    "\n",
    "# Avaliação do R² e MAPE usando cross-validation\n",
    "r2_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='r2')\n",
    "mape_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# Convertendo MAPE para valores positivos\n",
    "mape_scores = np.abs(mape_scores)\n",
    "\n",
    "print(f\"Cross-Validation R²: {r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "print(f\"Cross-Validation MAPE: {mape_scores.mean() * 100:.2f}% ± {mape_scores.std() * 100:.2f}%\")\n",
    "\n",
    "# Treinar o pipeline final com todos os dados\n",
    "pipeline.fit(X, y)\n",
    "print(\"Modelo final treinado com todos os dados.\")\n",
    "\n",
    "# Obter as features selecionadas pelo `SelectFromModel`\n",
    "selected_mask = pipeline.named_steps[\"select_from_model\"].get_support()\n",
    "selected_features = X.columns[selected_mask]\n",
    "print(\"\\nFeatures usadas no modelo final:\", selected_features.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-11T12:35:44.550453Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_filename = \"final_model_v1.pkl\"\n",
    "joblib.dump(pipeline, model_filename)\n",
    "print(\"Pipeline salvo como '{}'\".format(model_filename))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-10T04:11:34.661093Z",
     "start_time": "2025-03-10T04:11:29.520645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline salvo como 'final_model_v1.pkl'\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "sub_temp = pd.read_csv('../data/Submission_template.csv')\n",
    "sub_temp.rename(columns={\"Latitude\": \"latitude\", \"Longitude\": \"longitude\"}, inplace=True)\n",
    "features = []\n",
    "for _, row in sub_temp.iterrows():\n",
    "    lat, lon = row[\"latitude\"], row[\"longitude\"]\n",
    "    features.append(extract_features_from_dataframe(lat, lon, train_feat))\n",
    "\n",
    "val_features = pd.DataFrame(features)\n",
    "val_data_with_features = pd.concat([sub_temp.reset_index(drop=True), val_features.reset_index(drop=True)], axis=1)\n",
    "val_data_with_features = val_data_with_features.loc[:, ~val_data_with_features.columns.duplicated()]\n",
    "val_data_with_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-10T04:11:57.583586Z",
     "start_time": "2025-03-10T04:11:34.661093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      longitude   latitude  UHI Index              time  spatial_ref   B01  \\\n",
       "0    -73.971665  40.788763        NaN  24-07-2021 15:49         4326   811   \n",
       "1    -73.971928  40.788875        NaN  24-07-2021 15:49         4326  1208   \n",
       "2    -73.967080  40.789080        NaN  24-07-2021 15:49         4326   899   \n",
       "3    -73.972550  40.789082        NaN  24-07-2021 15:49         4326  1193   \n",
       "4    -73.969697  40.787953        NaN  24-07-2021 15:49         4326  1097   \n",
       "...         ...        ...        ...               ...          ...   ...   \n",
       "1035 -73.919388  40.813803        NaN  24-07-2021 15:49         4326  1474   \n",
       "1036 -73.931033  40.833178        NaN  24-07-2021 15:49         4326  1014   \n",
       "1037 -73.934647  40.854542        NaN  24-07-2021 15:49         4326  1268   \n",
       "1038 -73.917223  40.815413        NaN  24-07-2021 15:49         4326  1890   \n",
       "1039 -73.911645  40.804402        NaN  24-07-2021 15:49         4326  1252   \n",
       "\n",
       "       B02   B03   B04   B05   B06   B07   B08   B8A   B11   B12  distance  \n",
       "0      459   617   432   984  2089  2405  2502  2552  1474   893  0.000007  \n",
       "1      667   800   745  1112  2076  2248  2288  2445  1751  1188  0.000023  \n",
       "2      955  1052  1188   979   995  1158  1246  1056  1101   763  0.000042  \n",
       "3     1132  1364  1512  1866  1939  2076  1774  2196  2521  2346  0.000040  \n",
       "4     1506  1642  1688  1294  2204  2411  2834  2601  2248  1848  0.000015  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "1035  1086  1382  1474  1824  1553  1995  1578  1828  2421  2089  0.000025  \n",
       "1036   576   883   965  2034  2393  2701  2664  2679  2019  1201  0.000045  \n",
       "1037  1466  1608  1762  2040  2040  2246  1992  2184  2119  1682  0.000023  \n",
       "1038  1066  1244  1368  2302  2587  2621  2094  2723  3066  2379  0.000029  \n",
       "1039  1086  1372  1406  1699  1645  1790  1440  1730  1825  1593  0.000011  \n",
       "\n",
       "[1040 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>UHI Index</th>\n",
       "      <th>time</th>\n",
       "      <th>spatial_ref</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.971665</td>\n",
       "      <td>40.788763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>811</td>\n",
       "      <td>459</td>\n",
       "      <td>617</td>\n",
       "      <td>432</td>\n",
       "      <td>984</td>\n",
       "      <td>2089</td>\n",
       "      <td>2405</td>\n",
       "      <td>2502</td>\n",
       "      <td>2552</td>\n",
       "      <td>1474</td>\n",
       "      <td>893</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.971928</td>\n",
       "      <td>40.788875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1208</td>\n",
       "      <td>667</td>\n",
       "      <td>800</td>\n",
       "      <td>745</td>\n",
       "      <td>1112</td>\n",
       "      <td>2076</td>\n",
       "      <td>2248</td>\n",
       "      <td>2288</td>\n",
       "      <td>2445</td>\n",
       "      <td>1751</td>\n",
       "      <td>1188</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.967080</td>\n",
       "      <td>40.789080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>899</td>\n",
       "      <td>955</td>\n",
       "      <td>1052</td>\n",
       "      <td>1188</td>\n",
       "      <td>979</td>\n",
       "      <td>995</td>\n",
       "      <td>1158</td>\n",
       "      <td>1246</td>\n",
       "      <td>1056</td>\n",
       "      <td>1101</td>\n",
       "      <td>763</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.972550</td>\n",
       "      <td>40.789082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1193</td>\n",
       "      <td>1132</td>\n",
       "      <td>1364</td>\n",
       "      <td>1512</td>\n",
       "      <td>1866</td>\n",
       "      <td>1939</td>\n",
       "      <td>2076</td>\n",
       "      <td>1774</td>\n",
       "      <td>2196</td>\n",
       "      <td>2521</td>\n",
       "      <td>2346</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.969697</td>\n",
       "      <td>40.787953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1097</td>\n",
       "      <td>1506</td>\n",
       "      <td>1642</td>\n",
       "      <td>1688</td>\n",
       "      <td>1294</td>\n",
       "      <td>2204</td>\n",
       "      <td>2411</td>\n",
       "      <td>2834</td>\n",
       "      <td>2601</td>\n",
       "      <td>2248</td>\n",
       "      <td>1848</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>-73.919388</td>\n",
       "      <td>40.813803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1474</td>\n",
       "      <td>1086</td>\n",
       "      <td>1382</td>\n",
       "      <td>1474</td>\n",
       "      <td>1824</td>\n",
       "      <td>1553</td>\n",
       "      <td>1995</td>\n",
       "      <td>1578</td>\n",
       "      <td>1828</td>\n",
       "      <td>2421</td>\n",
       "      <td>2089</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>-73.931033</td>\n",
       "      <td>40.833178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1014</td>\n",
       "      <td>576</td>\n",
       "      <td>883</td>\n",
       "      <td>965</td>\n",
       "      <td>2034</td>\n",
       "      <td>2393</td>\n",
       "      <td>2701</td>\n",
       "      <td>2664</td>\n",
       "      <td>2679</td>\n",
       "      <td>2019</td>\n",
       "      <td>1201</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>-73.934647</td>\n",
       "      <td>40.854542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1268</td>\n",
       "      <td>1466</td>\n",
       "      <td>1608</td>\n",
       "      <td>1762</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2246</td>\n",
       "      <td>1992</td>\n",
       "      <td>2184</td>\n",
       "      <td>2119</td>\n",
       "      <td>1682</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>-73.917223</td>\n",
       "      <td>40.815413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1890</td>\n",
       "      <td>1066</td>\n",
       "      <td>1244</td>\n",
       "      <td>1368</td>\n",
       "      <td>2302</td>\n",
       "      <td>2587</td>\n",
       "      <td>2621</td>\n",
       "      <td>2094</td>\n",
       "      <td>2723</td>\n",
       "      <td>3066</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>-73.911645</td>\n",
       "      <td>40.804402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-07-2021 15:49</td>\n",
       "      <td>4326</td>\n",
       "      <td>1252</td>\n",
       "      <td>1086</td>\n",
       "      <td>1372</td>\n",
       "      <td>1406</td>\n",
       "      <td>1699</td>\n",
       "      <td>1645</td>\n",
       "      <td>1790</td>\n",
       "      <td>1440</td>\n",
       "      <td>1730</td>\n",
       "      <td>1825</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Exemplo: Criação de NDVI e SAVI\n",
    "val_data_with_features['NDVI'] = (val_data_with_features['B08'] - val_data_with_features['B04']) / (val_data_with_features['B08'] + val_data_with_features['B04'] + 1e-6)\n",
    "L = 0.5\n",
    "val_data_with_features['SAVI'] = ((val_data_with_features['B08'] - val_data_with_features['B04']) * (1 + L)) / (val_data_with_features['B08'] + val_data_with_features['B04'] + L + 1e-6)\n",
    "\n",
    "# Criação de NDBI\n",
    "val_data_with_features['NDBI'] = (val_data_with_features['B11'] - val_data_with_features['B08']) / (val_data_with_features['B11'] + val_data_with_features['B08'] + 1e-6)\n",
    "\n",
    "# Criação de MNDWI\n",
    "val_data_with_features['MNDWI'] = (val_data_with_features['B03'] - val_data_with_features['B11']) / (val_data_with_features['B03'] + val_data_with_features['B11'] + 1e-6)\n",
    "\n",
    "# Criação de EVI\n",
    "val_data_with_features['EVI'] = 2.5 * (val_data_with_features['B08'] - val_data_with_features['B04']) / (val_data_with_features['B08'] + 6 * val_data_with_features['B04'] - 7.5 * val_data_with_features['B02'] + 1)\n",
    "\n",
    "# val_data_with_features = val_data_with_features[['longitude', 'latitude', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06','B07', 'B08', 'B8A', 'B11', 'B12']]\n",
    "copy_val_data = val_data_with_features[['B01', 'B02', 'B03', 'B04', 'B05', 'B06','B07', 'B08', 'B8A', 'B11', 'B12', 'NDVI', 'SAVI', 'NDBI', 'MNDWI']].copy()\n",
    "pred_vals = pipeline.predict(copy_val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-10T04:11:58.754509Z",
     "start_time": "2025-03-10T04:11:57.663680Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "data_to_send = pd.DataFrame()\n",
    "data_to_send['UHI Index'] = pred_vals\n",
    "data_to_send['Latitude'] = val_data_with_features['latitude']\n",
    "data_to_send['Longitude'] = val_data_with_features['longitude']\n",
    "\n",
    "data_to_send = data_to_send[['Longitude', 'Latitude', 'UHI Index']]\n",
    "data_to_send.to_csv('../outputs/test_80_predicted_values.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-10T04:11:58.802059Z",
     "start_time": "2025-03-10T04:11:58.786258Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. Carregar e pré-processar os dados\n",
    "# ----------------------------------------\n",
    "\n",
    "# Supondo que `df_clean_factor5` esteja carregado no seu ambiente\n",
    "data = df_clean_factor5.copy()\n",
    "\n",
    "# Remover colunas irrelevantes\n",
    "cols_to_drop = [\n",
    "    \"latitude_x\", \"longitude_y\", \"latitude_y\", \"longitude_x\",\n",
    "    \"latitude\", \"longitude\", \"datetime\", \"distance\",\n",
    "    \"distance_meters\", \"time\", \"spatial_ref\", \"EVI\"\n",
    "]\n",
    "data = data.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Definir variável alvo (target)\n",
    "target = \"UHI Index\"\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Dividir em treino e teste (necessário para o LazyRegressor)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. Seleção de features usando ExtraTrees\n",
    "# ----------------------------------------\n",
    "\n",
    "# Selecionar features relevantes com ExtraTrees\n",
    "selector = SelectFromModel(\n",
    "    ExtraTreesRegressor(n_estimators=300, random_state=42),\n",
    "    threshold='1*mean'\n",
    ")\n",
    "\n",
    "# Fit selector apenas nos dados de treino\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Reduzir dados de treino e teste para features selecionadas\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Obter nomes das features selecionadas\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"\\n✅ Features selecionadas ({len(selected_features)}): {selected_features.tolist()}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. Normalização dos dados (StandardScaler)\n",
    "# ----------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. LazyRegressor - Rodar todos os modelos\n",
    "# ----------------------------------------\n",
    "\n",
    "# Instanciar LazyRegressor com máxima verbosidade\n",
    "lazy_regressor = LazyRegressor(verbose=1, ignore_warnings=False, custom_metric=None)\n",
    "\n",
    "# Fit LazyRegressor (automaticamente treina e avalia dezenas de modelos)\n",
    "models, predictions = lazy_regressor.fit(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# Exibir os resultados finais de todos os modelos ordenados por desempenho\n",
    "print(\"\\n🏅 Resultados completos dos modelos testados:\")\n",
    "print(models)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-10T16:57:30.499107Z",
     "start_time": "2025-03-10T04:11:58.802059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Features selecionadas (7): ['B01', 'B05', 'B06', 'B07', 'B8A', 'B11', 'B12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:05<03:30,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.12965449462550094, 'Adjusted R-Squared': 0.12953356771778524, 'RMSE': np.float64(0.01565004688803899), 'Time taken': 5.136677980422974}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/42 [00:14<05:04,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.9349815153217749, 'Adjusted R-Squared': 0.9349724815711, 'RMSE': np.float64(0.004277482283021543), 'Time taken': 9.351735830307007}\n",
      "{'Model': 'BayesianRidge', 'R-Squared': 0.08787064231905417, 'Adjusted R-Squared': 0.08774390990993619, 'RMSE': np.float64(0.016021309663830842), 'Time taken': 0.0681159496307373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/42 [00:15<02:04,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.939477235524832, 'Adjusted R-Squared': 0.9394688264152207, 'RMSE': np.float64(0.0041269497038525), 'Time taken': 1.2985453605651855}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -2.4062779576672355e-05, 'Adjusted R-Squared': -0.0001630073904312912, 'RMSE': np.float64(0.01677548259328708), 'Time taken': 0.02166271209716797}\n",
      "{'Model': 'ElasticNet', 'R-Squared': -2.4062779576672355e-05, 'Adjusted R-Squared': -0.0001630073904312912, 'RMSE': np.float64(0.01677548259328708), 'Time taken': 0.05158805847167969}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [00:16<00:53,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.08782146436057359, 'Adjusted R-Squared': 0.08769472511860776, 'RMSE': np.float64(0.016021741556892472), 'Time taken': 0.6700253486633301}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [00:16<00:42,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.9326500283732179, 'Adjusted R-Squared': 0.9326406706827912, 'RMSE': np.float64(0.004353499572532836), 'Time taken': 0.2620096206665039}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [00:39<02:32,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.956429790998697, 'Adjusted R-Squared': 0.9564237372986313, 'RMSE': np.float64(0.0035015845647282987), 'Time taken': 22.859192848205566}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': 0.06839890942587645, 'Adjusted R-Squared': 0.06826947158950913, 'RMSE': np.float64(0.016191414532671176), 'Time taken': 0.1553936004638672}\n",
      "GaussianProcessRegressor model failed to execute\n",
      "Unable to allocate 303. GiB for an array with shape (201552, 201552) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12/42 [01:02<03:42,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.17185488150040373, 'Adjusted R-Squared': 0.17173981796793114, 'RMSE': np.float64(0.015265921355743242), 'Time taken': 22.12544560432434}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 13/42 [01:02<02:48,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.2168443376378344, 'Adjusted R-Squared': 0.21673552499742355, 'RMSE': np.float64(0.01484546631048462), 'Time taken': 0.402968168258667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/42 [01:03<02:07,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HuberRegressor', 'R-Squared': 0.08766631261028834, 'Adjusted R-Squared': 0.08753955181134165, 'RMSE': np.float64(0.016023104061849033), 'Time taken': 0.7032721042633057}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 15/42 [01:04<01:37,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.686048438274272, 'Adjusted R-Squared': 0.6860048174463391, 'RMSE': np.float64(0.009399421419865583), 'Time taken': 0.977992057800293}\n",
      "KernelRidge model failed to execute\n",
      "Unable to allocate 303. GiB for an array with shape (201552, 201552) and data type float64\n",
      "{'Model': 'Lars', 'R-Squared': 0.08787716580441296, 'Adjusted R-Squared': 0.08775043430167628, 'RMSE': np.float64(0.016021252372085425), 'Time taken': 0.06370091438293457}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18/42 [01:04<00:42,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LarsCV', 'R-Squared': 0.08787716580441296, 'Adjusted R-Squared': 0.08775043430167628, 'RMSE': np.float64(0.016021252372085425), 'Time taken': 0.20237374305725098}\n",
      "{'Model': 'Lasso', 'R-Squared': -2.4062779576672355e-05, 'Adjusted R-Squared': -0.0001630073904312912, 'RMSE': np.float64(0.01677548259328708), 'Time taken': 0.04638266563415527}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [01:05<00:28,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoCV', 'R-Squared': 0.08782158074491486, 'Adjusted R-Squared': 0.08769484151911966, 'RMSE': np.float64(0.016021740534789986), 'Time taken': 0.6518111228942871}\n",
      "{'Model': 'LassoLars', 'R-Squared': -2.4062779576672355e-05, 'Adjusted R-Squared': -0.0001630073904312912, 'RMSE': np.float64(0.01677548259328708), 'Time taken': 0.03746986389160156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24/42 [01:05<00:11,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.08787716580441296, 'Adjusted R-Squared': 0.08775043430167628, 'RMSE': np.float64(0.016021252372085425), 'Time taken': 0.18646788597106934}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.08787716580441296, 'Adjusted R-Squared': 0.08775043430167628, 'RMSE': np.float64(0.016021252372085425), 'Time taken': 0.06368350982666016}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.08787716580441296, 'Adjusted R-Squared': 0.08775043430167628, 'RMSE': np.float64(0.016021252372085425), 'Time taken': 0.04468536376953125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 25/42 [01:13<00:33,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearSVR', 'R-Squared': 0.03607532711599193, 'Adjusted R-Squared': 0.035941398200126984, 'RMSE': np.float64(0.016469914550854454), 'Time taken': 7.813507556915283}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [01:15<00:32,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': 0.015147172809739096, 'Adjusted R-Squared': 0.015010336109587463, 'RMSE': np.float64(0.016647746939207186), 'Time taken': 2.405911922454834}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 29/42 [2:08:36<3:49:34, 1059.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'NuSVR', 'R-Squared': 0.1767526308489613, 'Adjusted R-Squared': 0.17663824781599136, 'RMSE': np.float64(0.015220712170476276), 'Time taken': 7641.04612159729}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.06659845773343287, 'Adjusted R-Squared': 0.06646876974002525, 'RMSE': np.float64(0.016207053086853877), 'Time taken': 0.041831016540527344}\n",
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.08750356116427627, 'Adjusted R-Squared': 0.08737677775243735, 'RMSE': np.float64(0.01602453318098674), 'Time taken': 0.10080409049987793}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [2:08:36<2:04:05, 676.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': -0.8603677347819745, 'Adjusted R-Squared': -0.8606262166331382, 'RMSE': np.float64(0.022880694208412336), 'Time taken': 0.07720017433166504}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.06831780995724479, 'Adjusted R-Squared': 0.06818836085281443, 'RMSE': np.float64(0.016192119279880894), 'Time taken': 0.031484365463256836}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [12:42:38<4:30:36, 1476.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 69\u001B[0m\n\u001B[0;32m     66\u001B[0m lazy_regressor \u001B[38;5;241m=\u001B[39m LazyRegressor(verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, ignore_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, custom_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# Fit LazyRegressor (automaticamente treina e avalia dezenas de modelos)\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m models, predictions \u001B[38;5;241m=\u001B[39m \u001B[43mlazy_regressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# Exibir os resultados finais de todos os modelos ordenados por desempenho\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m🏅 Resultados completos dos modelos testados:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\lazypredict\\Supervised.py:603\u001B[0m, in \u001B[0;36mLazyRegressor.fit\u001B[1;34m(self, X_train, X_test, y_train, y_test)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    599\u001B[0m     pipe \u001B[38;5;241m=\u001B[39m Pipeline(\n\u001B[0;32m    600\u001B[0m         steps\u001B[38;5;241m=\u001B[39m[(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpreprocessor\u001B[39m\u001B[38;5;124m\"\u001B[39m, preprocessor), (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregressor\u001B[39m\u001B[38;5;124m\"\u001B[39m, model())]\n\u001B[0;32m    601\u001B[0m     )\n\u001B[1;32m--> 603\u001B[0m \u001B[43mpipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels[name] \u001B[38;5;241m=\u001B[39m pipe\n\u001B[0;32m    605\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m pipe\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\sklearn\\pipeline.py:662\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    657\u001B[0m         last_step_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_metadata_for_step(\n\u001B[0;32m    658\u001B[0m             step_idx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m    659\u001B[0m             step_params\u001B[38;5;241m=\u001B[39mrouted_params[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]],\n\u001B[0;32m    660\u001B[0m             all_params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m    661\u001B[0m         )\n\u001B[1;32m--> 662\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mlast_step_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    664\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_quantile.py:259\u001B[0m, in \u001B[0;36mQuantileRegressor.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    255\u001B[0m         A_eq \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([X, \u001B[38;5;241m-\u001B[39mX, eye, \u001B[38;5;241m-\u001B[39meye], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    257\u001B[0m b_eq \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m--> 259\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mlinprog\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    260\u001B[0m \u001B[43m    \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_eq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mA_eq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mb_eq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mb_eq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    266\u001B[0m solution \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mx\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result\u001B[38;5;241m.\u001B[39msuccess:\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\scipy\\optimize\\_linprog.py:660\u001B[0m, in \u001B[0;36mlinprog\u001B[1;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001B[0m\n\u001B[0;32m    655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHiGHS solvers do not support the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    656\u001B[0m                               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallback interface.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    657\u001B[0m highs_solvers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighs-ipm\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mipm\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighs-ds\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimplex\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    658\u001B[0m                  \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhighs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m}\n\u001B[1;32m--> 660\u001B[0m sol \u001B[38;5;241m=\u001B[39m _linprog_highs(lp, solver\u001B[38;5;241m=\u001B[39mhighs_solvers[meth],\n\u001B[0;32m    661\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msolver_options)\n\u001B[0;32m    662\u001B[0m sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m], sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    663\u001B[0m     _check_result(sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m], sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfun\u001B[39m\u001B[38;5;124m'\u001B[39m], sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m], sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mslack\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    664\u001B[0m                   sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcon\u001B[39m\u001B[38;5;124m'\u001B[39m], lp\u001B[38;5;241m.\u001B[39mbounds, tol, sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    665\u001B[0m                   integrality))\n\u001B[0;32m    666\u001B[0m sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msuccess\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m sol[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\scipy\\optimize\\_linprog_highs.py:355\u001B[0m, in \u001B[0;36m_linprog_highs\u001B[1;34m(lp, solver, time_limit, presolve, disp, maxiter, dual_feasibility_tolerance, primal_feasibility_tolerance, ipm_optimality_tolerance, simplex_dual_edge_weight_strategy, mip_rel_gap, mip_max_nodes, **unknown_options)\u001B[0m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    353\u001B[0m     integrality \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(integrality)\n\u001B[1;32m--> 355\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43m_highs_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlhs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrhs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mlb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mub\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mintegrality\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;66;03m# HiGHS represents constraints as lhs/rhs, so\u001B[39;00m\n\u001B[0;32m    359\u001B[0m \u001B[38;5;66;03m# Ax + s = b => Ax = b - s\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;66;03m# and we need to split up s by A_ub and A_eq\u001B[39;00m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mslack\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m res:\n",
      "File \u001B[1;32m~\\PycharmProjects\\EY_DataChallenge_2025\\.venv\\lib\\site-packages\\scipy\\optimize\\_highspy\\_highs_wrapper.py:268\u001B[0m, in \u001B[0;36m_highs_wrapper\u001B[1;34m(c, indptr, indices, data, lhs, rhs, lb, ub, integrality, options)\u001B[0m\n\u001B[0;32m    266\u001B[0m marg_bnds \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m2\u001B[39m, numcol))\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ii \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(numcol):\n\u001B[1;32m--> 268\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m basis\u001B[38;5;241m.\u001B[39mcol_status[ii] \u001B[38;5;241m==\u001B[39m _h\u001B[38;5;241m.\u001B[39mHighsBasisStatus\u001B[38;5;241m.\u001B[39mkLower:\n\u001B[0;32m    269\u001B[0m         marg_bnds[\u001B[38;5;241m0\u001B[39m, ii] \u001B[38;5;241m=\u001B[39m solution\u001B[38;5;241m.\u001B[39mcol_dual[ii]\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m basis\u001B[38;5;241m.\u001B[39mcol_status[ii] \u001B[38;5;241m==\u001B[39m _h\u001B[38;5;241m.\u001B[39mHighsBasisStatus\u001B[38;5;241m.\u001B[39mkUpper:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:25:06.617053Z",
     "start_time": "2025-03-10T23:09:14.722481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Carregar Dados e Pré-processamento\n",
    "# ------------------------------\n",
    "data = df_clean_factor5.copy()\n",
    "\n",
    "cols_to_drop = [\"latitude_x\", \"longitude_y\", \"latitude_y\", \"longitude_x\",\n",
    "                \"latitude\", \"longitude\", \"datetime\", \"distance\",\n",
    "                \"distance_meters\", \"time\", \"spatial_ref\", \"EVI\"]\n",
    "data = data.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "target = \"UHI Index\"\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Obter Ranking Global das Features\n",
    "# ------------------------------\n",
    "et_all = ExtraTreesRegressor(n_estimators=300, random_state=42)\n",
    "et_all.fit(X, y)\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': et_all.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "sorted_features = feat_imp_df['Feature'].tolist()\n",
    "\n",
    "print(\"Ranked features by importance:\")\n",
    "print(feat_imp_df)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Seleção Forward Incremental com Exibição Imediata dos Resultados\n",
    "# ------------------------------\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = []\n",
    "current_subset = []  # Subconjunto atual de features\n",
    "\n",
    "for i, feature in enumerate(sorted_features, start=1):\n",
    "    current_subset.append(feature)\n",
    "    print(f\"\\nAdded feature: {feature}. Current subset: {current_subset}\")\n",
    "\n",
    "    X_subset = X[current_subset]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", ExtraTreesRegressor(random_state=42, n_estimators=600, max_depth=150, min_samples_split=2))\n",
    "    ])\n",
    "\n",
    "    r2_scores = cross_val_score(pipeline, X_subset, y, cv=kf, scoring='r2', n_jobs=-1)\n",
    "    mape_scores = np.abs(cross_val_score(pipeline, X_subset, y, cv=kf, scoring='neg_mean_absolute_percentage_error', n_jobs=-1))\n",
    "\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "    mean_mape = np.mean(mape_scores)\n",
    "    std_mape = np.std(mape_scores)\n",
    "\n",
    "    print(f\"CV R²: {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "    print(f\"CV MAPE: {mean_mape*100:.2f}% ± {std_mape*100:.2f}%\")\n",
    "\n",
    "    results.append({\n",
    "        'Num_features': i,\n",
    "        'Features': current_subset.copy(),\n",
    "        'R2_mean': mean_r2,\n",
    "        'R2_std': std_r2,\n",
    "        'MAPE_mean': mean_mape,\n",
    "        'MAPE_std': std_mape\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"forward_feature_selection_results.csv\", index=False)\n",
    "\n",
    "print(\"\\nSummary of forward feature selection results:\")\n",
    "print(results_df)\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Identificar o Melhor Conjunto (Menor MAPE)\n",
    "# ------------------------------\n",
    "best_idx = results_df['MAPE_mean'].idxmin()\n",
    "best_result = results_df.iloc[best_idx]\n",
    "print(\"\\nBest subset based on lowest cross-validation MAPE:\")\n",
    "print(best_result)\n",
    "\n",
    "joblib.dump(best_result, \"best_feature_subset.pkl\")\n",
    "print(\"\\nBest feature subset saved as 'best_feature_subset.pkl'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked features by importance:\n",
      "   Feature  Importance\n",
      "0      B01        0.22\n",
      "1      B05        0.09\n",
      "2      B12        0.09\n",
      "3      B07        0.08\n",
      "4      B8A        0.08\n",
      "5      B11        0.08\n",
      "6      B06        0.08\n",
      "7     SAVI        0.04\n",
      "8     NDVI        0.04\n",
      "9    MNDWI        0.04\n",
      "10     B02        0.04\n",
      "11     B03        0.04\n",
      "12    NDBI        0.03\n",
      "13     B04        0.03\n",
      "14     B08        0.03\n",
      "\n",
      "Added feature: B01. Current subset: ['B01']\n",
      "CV R²: 0.3824 ± 0.0053\n",
      "CV MAPE: 1.01% ± 0.01%\n",
      "\n",
      "Added feature: B05. Current subset: ['B01', 'B05']\n",
      "CV R²: 0.9506 ± 0.0025\n",
      "CV MAPE: 0.16% ± 0.00%\n",
      "\n",
      "Added feature: B12. Current subset: ['B01', 'B05', 'B12']\n",
      "CV R²: 0.9638 ± 0.0016\n",
      "CV MAPE: 0.14% ± 0.00%\n",
      "\n",
      "Added feature: B07. Current subset: ['B01', 'B05', 'B12', 'B07']\n",
      "CV R²: 0.9644 ± 0.0014\n",
      "CV MAPE: 0.14% ± 0.00%\n",
      "\n",
      "Added feature: B8A. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A']\n",
      "CV R²: 0.9645 ± 0.0013\n",
      "CV MAPE: 0.14% ± 0.00%\n",
      "\n",
      "Added feature: B11. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11']\n",
      "CV R²: 0.9646 ± 0.0013\n",
      "CV MAPE: 0.14% ± 0.00%\n",
      "\n",
      "Added feature: B06. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06']\n",
      "CV R²: 0.9646 ± 0.0014\n",
      "CV MAPE: 0.14% ± 0.00%\n",
      "\n",
      "Added feature: SAVI. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI']\n",
      "CV R²: 0.9326 ± 0.0015\n",
      "CV MAPE: 0.23% ± 0.00%\n",
      "\n",
      "Added feature: NDVI. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI']\n",
      "CV R²: 0.9046 ± 0.0021\n",
      "CV MAPE: 0.28% ± 0.00%\n",
      "\n",
      "Added feature: MNDWI. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI', 'MNDWI']\n",
      "CV R²: 0.8836 ± 0.0019\n",
      "CV MAPE: 0.32% ± 0.00%\n",
      "\n",
      "Added feature: B02. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI', 'MNDWI', 'B02']\n",
      "CV R²: 0.8585 ± 0.0026\n",
      "CV MAPE: 0.37% ± 0.00%\n",
      "\n",
      "Added feature: B03. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI', 'MNDWI', 'B02', 'B03']\n",
      "CV R²: 0.8387 ± 0.0027\n",
      "CV MAPE: 0.40% ± 0.00%\n",
      "\n",
      "Added feature: NDBI. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI', 'MNDWI', 'B02', 'B03', 'NDBI']\n",
      "CV R²: 0.8105 ± 0.0025\n",
      "CV MAPE: 0.43% ± 0.00%\n",
      "\n",
      "Added feature: B04. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI', 'MNDWI', 'B02', 'B03', 'NDBI', 'B04']\n",
      "CV R²: 0.7946 ± 0.0023\n",
      "CV MAPE: 0.46% ± 0.00%\n",
      "\n",
      "Added feature: B08. Current subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06', 'SAVI', 'NDVI', 'MNDWI', 'B02', 'B03', 'NDBI', 'B04', 'B08']\n",
      "CV R²: 0.7814 ± 0.0025\n",
      "CV MAPE: 0.47% ± 0.00%\n",
      "\n",
      "Summary of forward feature selection results:\n",
      "    Num_features                                           Features  R2_mean  \\\n",
      "0              1                                              [B01]     0.38   \n",
      "1              2                                         [B01, B05]     0.95   \n",
      "2              3                                    [B01, B05, B12]     0.96   \n",
      "3              4                               [B01, B05, B12, B07]     0.96   \n",
      "4              5                          [B01, B05, B12, B07, B8A]     0.96   \n",
      "5              6                     [B01, B05, B12, B07, B8A, B11]     0.96   \n",
      "6              7                [B01, B05, B12, B07, B8A, B11, B06]     0.96   \n",
      "7              8          [B01, B05, B12, B07, B8A, B11, B06, SAVI]     0.93   \n",
      "8              9    [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI]     0.90   \n",
      "9             10  [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI...     0.88   \n",
      "10            11  [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI...     0.86   \n",
      "11            12  [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI...     0.84   \n",
      "12            13  [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI...     0.81   \n",
      "13            14  [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI...     0.79   \n",
      "14            15  [B01, B05, B12, B07, B8A, B11, B06, SAVI, NDVI...     0.78   \n",
      "\n",
      "    R2_std  MAPE_mean  MAPE_std  \n",
      "0     0.01       0.01      0.00  \n",
      "1     0.00       0.00      0.00  \n",
      "2     0.00       0.00      0.00  \n",
      "3     0.00       0.00      0.00  \n",
      "4     0.00       0.00      0.00  \n",
      "5     0.00       0.00      0.00  \n",
      "6     0.00       0.00      0.00  \n",
      "7     0.00       0.00      0.00  \n",
      "8     0.00       0.00      0.00  \n",
      "9     0.00       0.00      0.00  \n",
      "10    0.00       0.00      0.00  \n",
      "11    0.00       0.00      0.00  \n",
      "12    0.00       0.00      0.00  \n",
      "13    0.00       0.00      0.00  \n",
      "14    0.00       0.00      0.00  \n",
      "\n",
      "Best subset based on lowest cross-validation MAPE:\n",
      "Num_features                                 6\n",
      "Features        [B01, B05, B12, B07, B8A, B11]\n",
      "R2_mean                                   0.96\n",
      "R2_std                                    0.00\n",
      "MAPE_mean                                 0.00\n",
      "MAPE_std                                  0.00\n",
      "Name: 5, dtype: object\n",
      "\n",
      "Best feature subset saved as 'best_feature_subset.pkl'\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T02:39:56.896656Z",
     "start_time": "2025-03-11T02:25:06.990491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ------------------------------\n",
    "# Assume previous forward selection results are saved in results_df\n",
    "# results_df should have columns: 'Num_features', 'Features', 'R2_mean', 'R2_std', 'MAPE_mean', 'MAPE_std'\n",
    "# ------------------------------\n",
    "# For demonstration, let's load results_df from CSV (if previously saved)\n",
    "results_df = pd.read_csv(\"forward_feature_selection_results.csv\")\n",
    "\n",
    "# Convert the string representation of list back to a list (if necessary)\n",
    "# Here we assume 'Features' column is stored as a string representation of list\n",
    "import ast\n",
    "results_df['Features'] = results_df['Features'].apply(ast.literal_eval)\n",
    "\n",
    "# Get the top 3 best feature subsets based on lowest MAPE_mean\n",
    "top3 = results_df.nsmallest(3, 'MAPE_mean')\n",
    "print(\"Top 3 best feature subsets based on CV MAPE:\")\n",
    "print(top3[['Num_features', 'Features', 'MAPE_mean']])\n",
    "\n",
    "# Define cross-validation scheme\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring: use negative MAPE so that higher is better in GridSearchCV\n",
    "scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "\n",
    "# Define parameter grids for LGBMRegressor and XGBRegressor\n",
    "param_grid_lgbm = {\n",
    "    'model__n_estimators': [100, 300, 600],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'model__n_estimators': [100, 300, 600],\n",
    "    'model__max_depth': [3, 6, 10],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Prepare to store the best model info\n",
    "best_overall_score = np.inf  # Lower MAPE is better\n",
    "best_pipeline = None\n",
    "best_features = None\n",
    "best_model_name = None\n",
    "results_list = []  # To log all tuning experiments\n",
    "\n",
    "# Loop over each of the top 3 feature subsets\n",
    "for idx, row in top3.iterrows():\n",
    "    features_subset = row['Features']\n",
    "    print(f\"\\nTuning for feature subset: {features_subset}\")\n",
    "\n",
    "    # Subset X for current feature set\n",
    "    X_subset = X[features_subset]\n",
    "\n",
    "    # Define common pipeline structure: scaling then model\n",
    "    for model_name, regressor, param_grid in [\n",
    "        ('LGBMRegressor', LGBMRegressor(random_state=42), param_grid_lgbm),\n",
    "        ('XGBRegressor', XGBRegressor(random_state=42, objective='reg:squarederror'), param_grid_xgb)\n",
    "    ]:\n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", regressor)\n",
    "        ])\n",
    "\n",
    "        print(f\"  Tuning {model_name}...\")\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=kf,\n",
    "            scoring=scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid_search.fit(X_subset, y)\n",
    "\n",
    "        best_score = -grid_search.best_score_  # Convert back to positive MAPE\n",
    "        print(f\"    Best {model_name} MAPE: {best_score:.4f} (params: {grid_search.best_params_})\")\n",
    "\n",
    "        # Save details\n",
    "        results_list.append({\n",
    "            'Model': model_name,\n",
    "            'Features': features_subset,\n",
    "            'Num_features': len(features_subset),\n",
    "            'Best_MAPE': best_score,\n",
    "            'Best_Params': grid_search.best_params_\n",
    "        })\n",
    "\n",
    "        # Check if this is the best overall model\n",
    "        if best_score < best_overall_score:\n",
    "            best_overall_score = best_score\n",
    "            best_pipeline = grid_search.best_estimator_\n",
    "            best_features = features_subset\n",
    "            best_model_name = model_name\n",
    "\n",
    "# Save the tuning experiments results as a DataFrame\n",
    "tuning_results_df = pd.DataFrame(results_list)\n",
    "tuning_results_df.to_csv(\"tuning_results.csv\", index=False)\n",
    "print(\"\\nTuning experiments results:\")\n",
    "print(tuning_results_df)\n",
    "\n",
    "# Save the best overall model\n",
    "joblib.dump(best_pipeline, \"best_model_pipeline.pkl\")\n",
    "print(\"\\nBest overall model saved!\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Features: {best_features}\")\n",
    "print(f\"Best MAPE: {best_overall_score:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 best feature subsets based on CV MAPE:\n",
      "   Num_features                             Features  MAPE_mean\n",
      "5             6       [B01, B05, B12, B07, B8A, B11]       0.00\n",
      "6             7  [B01, B05, B12, B07, B8A, B11, B06]       0.00\n",
      "3             4                 [B01, B05, B12, B07]       0.00\n",
      "\n",
      "Tuning for feature subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11']\n",
      "  Tuning LGBMRegressor...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 251941, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 0.998999\n",
      "    Best LGBMRegressor MAPE: 0.0106 (params: {'model__learning_rate': 0.1, 'model__max_depth': 20, 'model__n_estimators': 600})\n",
      "  Tuning XGBRegressor...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "    Best XGBRegressor MAPE: 0.0045 (params: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8})\n",
      "\n",
      "Tuning for feature subset: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06']\n",
      "  Tuning LGBMRegressor...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1785\n",
      "[LightGBM] [Info] Number of data points in the train set: 251941, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 0.998999\n",
      "    Best LGBMRegressor MAPE: 0.0105 (params: {'model__learning_rate': 0.1, 'model__max_depth': None, 'model__n_estimators': 600})\n",
      "  Tuning XGBRegressor...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "    Best XGBRegressor MAPE: 0.0044 (params: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8})\n",
      "\n",
      "Tuning for feature subset: ['B01', 'B05', 'B12', 'B07']\n",
      "  Tuning LGBMRegressor...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 251941, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 0.998999\n",
      "    Best LGBMRegressor MAPE: 0.0108 (params: {'model__learning_rate': 0.1, 'model__max_depth': None, 'model__n_estimators': 600})\n",
      "  Tuning XGBRegressor...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "    Best XGBRegressor MAPE: 0.0051 (params: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8})\n",
      "\n",
      "Tuning experiments results:\n",
      "           Model                             Features  Num_features  \\\n",
      "0  LGBMRegressor       [B01, B05, B12, B07, B8A, B11]             6   \n",
      "1   XGBRegressor       [B01, B05, B12, B07, B8A, B11]             6   \n",
      "2  LGBMRegressor  [B01, B05, B12, B07, B8A, B11, B06]             7   \n",
      "3   XGBRegressor  [B01, B05, B12, B07, B8A, B11, B06]             7   \n",
      "4  LGBMRegressor                 [B01, B05, B12, B07]             4   \n",
      "5   XGBRegressor                 [B01, B05, B12, B07]             4   \n",
      "\n",
      "   Best_MAPE                                        Best_Params  \n",
      "0       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "1       0.00  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "2       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "3       0.00  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "4       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "5       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
      "\n",
      "Best overall model saved!\n",
      "Model: XGBRegressor\n",
      "Features: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06']\n",
      "Best MAPE: 0.0044\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T04:15:45.337210Z",
     "start_time": "2025-03-11T04:15:45.325132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_copy_val_data = copy_val_data[best_features]\n",
    "pred_vals_fin = best_pipeline.predict(final_copy_val_data)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T04:15:48.340820Z",
     "start_time": "2025-03-11T04:15:48.327825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_to_send_fin = pd.DataFrame()\n",
    "data_to_send_fin['UHI Index'] = pred_vals_fin\n",
    "data_to_send_fin['Latitude'] = val_data_with_features['latitude']\n",
    "data_to_send_fin['Longitude'] = val_data_with_features['longitude']\n",
    "\n",
    "data_to_send_fin = data_to_send_fin[['Longitude', 'Latitude', 'UHI Index']]\n",
    "data_to_send_fin.to_csv('../outputs/xgb_predicted_values.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T04:30:23.468311Z",
     "start_time": "2025-03-11T04:30:23.454560Z"
    }
   },
   "cell_type": "code",
   "source": "tuning_results_df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Model                             Features  Num_features  \\\n",
       "0  LGBMRegressor       [B01, B05, B12, B07, B8A, B11]             6   \n",
       "1   XGBRegressor       [B01, B05, B12, B07, B8A, B11]             6   \n",
       "2  LGBMRegressor  [B01, B05, B12, B07, B8A, B11, B06]             7   \n",
       "3   XGBRegressor  [B01, B05, B12, B07, B8A, B11, B06]             7   \n",
       "4  LGBMRegressor                 [B01, B05, B12, B07]             4   \n",
       "5   XGBRegressor                 [B01, B05, B12, B07]             4   \n",
       "\n",
       "   Best_MAPE                                        Best_Params  \n",
       "0       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
       "1       0.00  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
       "2       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
       "3       0.00  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
       "4       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  \n",
       "5       0.01  {'model__learning_rate': 0.1, 'model__max_dept...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Num_features</th>\n",
       "      <th>Best_MAPE</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[B01, B05, B12, B07, B8A, B11]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[B01, B05, B12, B07, B8A, B11]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[B01, B05, B12, B07, B8A, B11, B06]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[B01, B05, B12, B07, B8A, B11, B06]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[B01, B05, B12, B07]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[B01, B05, B12, B07]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T12:29:16.436274Z",
     "start_time": "2025-03-11T12:26:24.878827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Assume X and y are already defined from your preprocessed data.\n",
    "# Also assume best_features is defined from your previous tuning, e.g.:\n",
    "best_features = ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06']\n",
    "\n",
    "# Subset the data to the best features\n",
    "X_best = X[best_features]\n",
    "\n",
    "# Define cross-validation scheme and scoring metrics\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Negative MAPE scorer so that higher values indicate lower error\n",
    "scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "\n",
    "# Define candidate parameter sets (including options with reduced n_estimators)\n",
    "candidate_params = [\n",
    "    {'model__learning_rate': 0.05, 'model__max_depth': 10, 'model__n_estimators': 300, 'model__subsample': 0.8},\n",
    "    {'model__learning_rate': 0.1,  'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8, 'model__reg_lambda': 1},\n",
    "    {'model__learning_rate': 0.1,  'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8, 'model__reg_alpha': 0.1},\n",
    "    {'model__learning_rate': 0.1,  'model__max_depth': 8,  'model__n_estimators': 300, 'model__subsample': 0.8},\n",
    "    {'model__learning_rate': 0.1,  'model__max_depth': 10, 'model__n_estimators': 300, 'model__subsample': 0.8, 'model__colsample_bytree': 0.8},\n",
    "    {'model__learning_rate': 0.1,  'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.7},\n",
    "    {'model__learning_rate': 0.05, 'model__max_depth': 10, 'model__n_estimators': 400, 'model__subsample': 0.8},\n",
    "    {'model__learning_rate': 0.05, 'model__max_depth': 8,  'model__n_estimators': 300, 'model__subsample': 0.8, 'model__reg_lambda': 1, 'model__reg_alpha': 0.1},\n",
    "    {'model__learning_rate': 0.1,  'model__max_depth': 8,  'model__n_estimators': 300, 'model__subsample': 0.7, 'model__colsample_bytree': 0.8},\n",
    "    {'model__learning_rate': 0.05, 'model__max_depth': 8,  'model__n_estimators': 200, 'model__subsample': 0.7, 'model__reg_lambda': 1, 'model__colsample_bytree': 0.8}\n",
    "]\n",
    "\n",
    "# List to store results from all candidate experiments\n",
    "overfitting_results = []\n",
    "\n",
    "print(\"\\nRunning experiments to reduce overfitting (including reducing n_estimators):\")\n",
    "# Loop over each candidate parameter set\n",
    "for i, params in enumerate(candidate_params, start=1):\n",
    "    print(f\"\\nExperiment {i} with parameters: {params}\")\n",
    "    # Build a pipeline with StandardScaler and XGBRegressor\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"model\", XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "    ])\n",
    "    # Set candidate parameters in the pipeline\n",
    "    pipeline.set_params(**params)\n",
    "\n",
    "    # Evaluate using cross-validation: MAPE and R²\n",
    "    mape_scores = cross_val_score(pipeline, X_best, y, cv=kf, scoring=scorer, n_jobs=-1)\n",
    "    cv_mape = -np.mean(mape_scores)  # Convert negative MAPE to positive value\n",
    "    mape_std = np.std(-mape_scores)\n",
    "\n",
    "    r2_scores = cross_val_score(pipeline, X_best, y, cv=kf, scoring='r2', n_jobs=-1)\n",
    "    cv_r2 = np.mean(r2_scores)\n",
    "    r2_std = np.std(r2_scores)\n",
    "\n",
    "    print(f\"CV MAPE: {cv_mape:.4f} (std: {mape_std:.4f}) | CV R²: {cv_r2:.4f} (std: {r2_std:.4f})\")\n",
    "\n",
    "    overfitting_results.append({\n",
    "        'Experiment': i,\n",
    "        'Parameters': params,\n",
    "        'CV_MAPE_mean': cv_mape,\n",
    "        'CV_MAPE_std': mape_std,\n",
    "        'CV_R2_mean': cv_r2,\n",
    "        'CV_R2_std': r2_std\n",
    "    })\n",
    "\n",
    "# Convert experiment results to a DataFrame and sort by CV_MAPE_mean\n",
    "overfitting_df = pd.DataFrame(overfitting_results).sort_values(by='CV_MAPE_mean')\n",
    "print(\"\\nOverfitting Reduction Experiments Results:\")\n",
    "print(overfitting_df)\n",
    "\n",
    "# Save the full experiments DataFrame to a CSV file\n",
    "overfitting_df.to_csv(\"overfitting_reduction_experiments.csv\", index=False)\n",
    "\n",
    "# Select the best candidate experiment (lowest CV_MAPE_mean)\n",
    "best_candidate = overfitting_df.iloc[0]\n",
    "print(\"\\nBest candidate experiment:\")\n",
    "print(best_candidate)\n",
    "\n",
    "# Re-fit the best candidate pipeline on the entire training data using the best features\n",
    "best_params_candidate = best_candidate['Parameters']\n",
    "final_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "final_pipeline.set_params(**best_params_candidate)\n",
    "final_pipeline.fit(X_best, y)\n",
    "\n",
    "# Save the final refined model\n",
    "joblib.dump(final_pipeline, \"best_model_overfitting_refined.pkl\")\n",
    "print(\"\\nFinal refined model saved!\")\n",
    "print(f\"Model: XGBRegressor\")\n",
    "print(f\"Features: {best_features}\")\n",
    "print(f\"Best CV MAPE after overfitting reduction experiments: {best_candidate['CV_MAPE_mean']:.4f}\")\n",
    "print(f\"Best CV R²: {best_candidate['CV_R2_mean']:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiments to reduce overfitting (including reducing n_estimators):\n",
      "\n",
      "Experiment 1 with parameters: {'model__learning_rate': 0.05, 'model__max_depth': 10, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "CV MAPE: 0.0086 (std: 0.0001) | CV R²: 0.5675 (std: 0.0042)\n",
      "\n",
      "Experiment 2 with parameters: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8, 'model__reg_lambda': 1}\n",
      "CV MAPE: 0.0044 (std: 0.0000) | CV R²: 0.8679 (std: 0.0018)\n",
      "\n",
      "Experiment 3 with parameters: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.8, 'model__reg_alpha': 0.1}\n",
      "CV MAPE: 0.0058 (std: 0.0000) | CV R²: 0.7853 (std: 0.0026)\n",
      "\n",
      "Experiment 4 with parameters: {'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "CV MAPE: 0.0091 (std: 0.0001) | CV R²: 0.5215 (std: 0.0018)\n",
      "\n",
      "Experiment 5 with parameters: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 300, 'model__subsample': 0.8, 'model__colsample_bytree': 0.8}\n",
      "CV MAPE: 0.0069 (std: 0.0000) | CV R²: 0.7130 (std: 0.0013)\n",
      "\n",
      "Experiment 6 with parameters: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 600, 'model__subsample': 0.7}\n",
      "CV MAPE: 0.0043 (std: 0.0000) | CV R²: 0.8702 (std: 0.0031)\n",
      "\n",
      "Experiment 7 with parameters: {'model__learning_rate': 0.05, 'model__max_depth': 10, 'model__n_estimators': 400, 'model__subsample': 0.8}\n",
      "CV MAPE: 0.0079 (std: 0.0000) | CV R²: 0.6325 (std: 0.0041)\n",
      "\n",
      "Experiment 8 with parameters: {'model__learning_rate': 0.05, 'model__max_depth': 8, 'model__n_estimators': 300, 'model__subsample': 0.8, 'model__reg_lambda': 1, 'model__reg_alpha': 0.1}\n",
      "CV MAPE: 0.0105 (std: 0.0000) | CV R²: 0.3731 (std: 0.0014)\n",
      "\n",
      "Experiment 9 with parameters: {'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__n_estimators': 300, 'model__subsample': 0.7, 'model__colsample_bytree': 0.8}\n",
      "CV MAPE: 0.0093 (std: 0.0000) | CV R²: 0.5082 (std: 0.0018)\n",
      "\n",
      "Experiment 10 with parameters: {'model__learning_rate': 0.05, 'model__max_depth': 8, 'model__n_estimators': 200, 'model__subsample': 0.7, 'model__reg_lambda': 1, 'model__colsample_bytree': 0.8}\n",
      "CV MAPE: 0.0109 (std: 0.0000) | CV R²: 0.3351 (std: 0.0030)\n",
      "\n",
      "Overfitting Reduction Experiments Results:\n",
      "   Experiment                                         Parameters  \\\n",
      "5           6  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "1           2  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "2           3  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "4           5  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "6           7  {'model__learning_rate': 0.05, 'model__max_dep...   \n",
      "0           1  {'model__learning_rate': 0.05, 'model__max_dep...   \n",
      "3           4  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "8           9  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "7           8  {'model__learning_rate': 0.05, 'model__max_dep...   \n",
      "9          10  {'model__learning_rate': 0.05, 'model__max_dep...   \n",
      "\n",
      "   CV_MAPE_mean  CV_MAPE_std  CV_R2_mean  CV_R2_std  \n",
      "5          0.00         0.00        0.87       0.00  \n",
      "1          0.00         0.00        0.87       0.00  \n",
      "2          0.01         0.00        0.79       0.00  \n",
      "4          0.01         0.00        0.71       0.00  \n",
      "6          0.01         0.00        0.63       0.00  \n",
      "0          0.01         0.00        0.57       0.00  \n",
      "3          0.01         0.00        0.52       0.00  \n",
      "8          0.01         0.00        0.51       0.00  \n",
      "7          0.01         0.00        0.37       0.00  \n",
      "9          0.01         0.00        0.34       0.00  \n",
      "\n",
      "Best candidate experiment:\n",
      "Experiment                                                      6\n",
      "Parameters      {'model__learning_rate': 0.1, 'model__max_dept...\n",
      "CV_MAPE_mean                                                 0.00\n",
      "CV_MAPE_std                                                  0.00\n",
      "CV_R2_mean                                                   0.87\n",
      "CV_R2_std                                                    0.00\n",
      "Name: 5, dtype: object\n",
      "\n",
      "Final refined model saved!\n",
      "Model: XGBRegressor\n",
      "Features: ['B01', 'B05', 'B12', 'B07', 'B8A', 'B11', 'B06']\n",
      "Best CV MAPE after overfitting reduction experiments: 0.0043\n",
      "Best CV R²: 0.8702\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
